{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1fOf8024sT6",
    "outputId": "85420f99-54f9-4451-a73b-3a2b81f83784"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set GPU configuration to use NVIDIA CUDA devices\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "id": "g-4ip0Pm_mTs",
    "ExecuteTime": {
     "end_time": "2024-12-08T02:20:28.379354Z",
     "start_time": "2024-12-08T02:20:24.998328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 20:20:25.676768: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-07 20:20:25.813512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733624425.864852     454 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733624425.879998     454 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 20:20:26.010766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:26:49.735878Z",
     "start_time": "2024-12-08T04:26:49.726020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all physical devices\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"All Physical Devices:\", physical_devices)\n",
    "\n",
    "# List only GPU devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs Available:\", gpus)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Physical Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPUs Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "M6IP5GDs233A",
    "outputId": "6afc5c6c-e3c0-4941-90f8-7ed06a2a4e99",
    "ExecuteTime": {
     "end_time": "2024-12-08T02:20:54.656080Z",
     "start_time": "2024-12-08T02:20:28.649553Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Load or distribute your data here\n",
    "home = r'mnt/e/BigRun'\n",
    "#resolution = home + 'TFDL_BigRunWS_V5_TS_500'\n",
    "train_file = r\"/mnt/e/BigRun/train/BigRunWS_V5_T_500_train_part_1.csv\"\n",
    "test_file = r\"/mnt/e/BigRun/test/BigRunWS_V5_T_500_test_part_1.csv\"\n",
    "\n",
    "train_data_full = pd.read_csv(train_file, usecols=['PageName', 'Clay', 'Sand', 'Silt', 'Elevation', 'Slope', 'Aspect', 'MODIS', 'Smerge', 'Date', 'LAI', 'ALB', 'Temp'], engine='pyarrow')\n",
    "test_data_full = pd.read_csv(test_file, usecols=['PageName', 'Clay', 'Sand', 'Silt', 'Elevation', 'Slope', 'Aspect', 'MODIS', 'Smerge', 'Date', 'LAI', 'ALB', 'Temp', 'AHRR'], engine='pyarrow')\n",
    "\n",
    "train_data = train_data_full[['Clay', 'Sand', 'Silt', 'Elevation', 'Aspect', 'Slope', 'MODIS', 'Smerge', 'Date', 'LAI', 'ALB', 'Temp']].dropna()\n",
    "test_data = test_data_full[['Clay', 'Sand', 'Silt', 'Elevation', 'Aspect', 'Slope', 'MODIS', 'Smerge', 'Date', 'LAI', 'ALB', 'Temp']].dropna()\n",
    "\n",
    "modis = test_data_full['MODIS']\n",
    "dates = test_data_full['Date']\n",
    "ahrr = test_data_full['AHRR']\n",
    "test_page = test_data_full[['PageName']]\n",
    "\n",
    "# Convert Date to a numerical value\n",
    "test_data['Date'] = pd.to_datetime(test_data['Date'], format=\"%Y-%m-%d\").astype(int)\n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'], format=\"%Y-%m-%d\").astype(int)\n",
    "\n",
    "# Split features and labels\n",
    "X_train = train_data[['Clay', 'Sand', 'Silt', 'Elevation', 'Aspect', 'Slope', 'MODIS', 'LAI', 'ALB', 'Temp', \"Date\"]]\n",
    "y_train = train_data['Smerge']\n",
    "X_test = test_data[['Clay', 'Sand', 'Silt', 'Elevation', 'Aspect', 'Slope', 'MODIS', 'LAI', 'ALB', 'Temp', \"Date\"]]\n",
    "y_test = test_data['Smerge']\n",
    "\n",
    "# Standardize features\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:10:35.078367Z",
     "start_time": "2024-12-08T02:21:53.782070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model()\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict on the test dataset\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "test_data['ML_'] = pred\n",
    "test_data['MODIS'] = modis\n",
    "test_data['Date'] = dates\n",
    "test_data['PageName'] = test_page\n",
    "test_data['AHRR'] = ahrr\n",
    "test_data.to_csv(\"mnt/e/BigRun/TFDL_BigRunWS_V5_TS_500.csv\", index=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asancchez/.local/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1733624516.048856     454 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9536 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733624518.064782     856 service.cc:148] XLA service 0x7fa35000cb90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733624518.065213     856 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2024-12-07 20:21:58.087176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733624518.164328     856 cuda_dnn.cc:529] Loaded cuDNN version 90600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m   101/372339\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m9:28\u001B[0m 2ms/step - loss: 0.0084 - mae: 0.0699 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733624519.154385     856 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m372339/372339\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m596s\u001B[0m 2ms/step - loss: 0.0013 - mae: 0.0272\n",
      "Epoch 2/50\n",
      "\u001B[1m372339/372339\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m603s\u001B[0m 2ms/step - loss: 0.0011 - mae: 0.0253\n",
      "Epoch 3/50\n",
      "\u001B[1m372339/372339\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m601s\u001B[0m 2ms/step - loss: 0.0011 - mae: 0.0249\n",
      "Epoch 4/50\n",
      "\u001B[1m372339/372339\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m576s\u001B[0m 2ms/step - loss: 0.0011 - mae: 0.0246\n",
      "Epoch 5/50\n",
      "\u001B[1m359636/372339\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m19s\u001B[0m 2ms/step - loss: 0.0011 - mae: 0.0243"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Build and train the model\u001B[39;00m\n\u001B[1;32m     18\u001B[0m model \u001B[38;5;241m=\u001B[39m build_model()\n\u001B[0;32m---> 19\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Predict on the test dataset\u001B[39;00m\n\u001B[1;32m     22\u001B[0m pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[1;32m    367\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 368\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n\u001B[1;32m    370\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:217\u001B[0m, in \u001B[0;36mTensorFlowTrainer._make_function.<locals>.function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[1;32m    214\u001B[0m     iterator, (tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mIterator, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedIterator)\n\u001B[1;32m    215\u001B[0m ):\n\u001B[1;32m    216\u001B[0m     opt_outputs \u001B[38;5;241m=\u001B[39m multi_step_on_iterator(iterator)\n\u001B[0;32m--> 217\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mopt_outputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mget_value()\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001B[0m, in \u001B[0;36m_OptionalImpl.has_value\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhas_value\u001B[39m(\u001B[38;5;28mself\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    175\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[0;32m--> 176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_optional_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptional_has_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variant_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001B[0m, in \u001B[0;36moptional_has_value\u001B[0;34m(optional, name)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m    171\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 172\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mOptionalHasValue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptional\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m    175\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU is available: \", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSmOzvV-7dwY",
    "outputId": "559f81eb-4a7d-4b35-f338-bac5f94c0f01"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU is available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data_full_1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/TFDL_BigRunWS_V5_TS_500.csv\", engine='pyarrow')\n",
    "test_file = '/content/drive/MyDrive/Colab Notebooks/BigRunWS_V5_L_500_test_part_10.csv'\n",
    "test_data_full = pd.read_csv(test_file, engine='pyarrow')"
   ],
   "metadata": {
    "id": "w2waKODaHy1p"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_data_full['ML_'] = test_data_full_1['ML_']\n",
    "print(test_data_full)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FW1UeweJItUI",
    "outputId": "1816d261-d182-4b09-bc15-71c298569916"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        PageName        Date      Aspect       Clay   Elevation       Sand  \\\n",
      "0          EL203  2009-05-07  181.281639   5.761240  535.269261  83.761319   \n",
      "1          ES456  2009-06-20  222.426775  40.332804  418.311052   4.703199   \n",
      "2          HZ272  2016-09-08  144.423113  12.902163  464.717362  68.472239   \n",
      "3          DD319  2012-06-01  215.834175   4.937830  481.469028  87.231289   \n",
      "4          RY566  2009-08-25  135.303861  16.521910  274.776140  52.549591   \n",
      "...          ...         ...         ...        ...         ...        ...   \n",
      "2172342    HT281  2015-06-03  162.454179  17.897157  481.203375  52.336996   \n",
      "2172343    SD641  2009-06-02  160.167098  32.830077  196.057226  14.691847   \n",
      "2172344    IU307  2015-04-25  163.371199  22.945723  424.049061  46.298830   \n",
      "2172345    EZ152  2009-05-25  157.423177  14.929941  587.792622  64.321923   \n",
      "2172346    GT482  2012-05-03  195.322385  29.674426  399.328221  13.258646   \n",
      "\n",
      "              Silt     Slope    Smerge      ALB    LAI       Temp   MODIS  \\\n",
      "0        10.477474  1.260349  0.159797  0.06525  1.275  20.318001  171.50   \n",
      "1        54.963999  1.721093  0.315149  0.04600  2.000  26.526001  171.00   \n",
      "2        18.625553  1.623486  0.207194  0.07150  0.950  27.553001  160.25   \n",
      "3         7.830913  2.090309  0.098741  0.07025  1.675  14.531001  164.50   \n",
      "4        30.928518  5.129941  0.224412  0.03900  1.500  25.076002  174.00   \n",
      "...            ...       ...       ...      ...    ...        ...     ...   \n",
      "2172342  29.765846  1.600221  0.229563  0.08500  0.775  25.253000  154.75   \n",
      "2172343  52.478076  1.198686  0.253885  0.06575  1.350  25.576002  161.50   \n",
      "2172344  30.755430  1.034999  0.246136  0.06150  1.100  19.063002  162.75   \n",
      "2172345  20.748136  0.409152  0.102825  0.06800  0.600  21.327002  155.50   \n",
      "2172346  57.066912  2.155783  0.278534  0.04675  1.675  23.635000  168.60   \n",
      "\n",
      "            AHRR        PPT       ML_  \n",
      "0        0.47210   0.000000  0.188689  \n",
      "1        0.62110   3.007000  0.325666  \n",
      "2        0.41780  20.162001  0.199101  \n",
      "3        0.35475   0.000000  0.141368  \n",
      "4        0.00740   0.000000  0.230392  \n",
      "...          ...        ...       ...  \n",
      "2172342  0.47070   0.000000  0.261429  \n",
      "2172343  0.55370   0.000000  0.260987  \n",
      "2172344  0.01480   0.323000  0.269101  \n",
      "2172345  0.48810   0.000000  0.188294  \n",
      "2172346  0.59350   0.000000  0.316649  \n",
      "\n",
      "[2172347 rows x 16 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data_full.to_csv(\"/content/drive/MyDrive/Colab Notebooks/TFDL_BigRunWS_V5_TS_500_2.csv\", index=False)"
   ],
   "metadata": {
    "id": "WwL7dyyTJG6N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZGwtFD97hUV",
    "outputId": "b6c5a989-1883-4041-ecff-7276e5152992"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tue Nov 26 19:43:42 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
      "| N/A   43C    P8              16W /  72W |      4MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a simple model for testing\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data to use with the model\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.random.random((10000, 784))\n",
    "y_train = np.random.randint(10, size=(10000,))\n",
    "\n",
    "# Train the model (this will utilize the GPU if available)\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)\n"
   ],
   "metadata": {
    "id": "378e_S1LHpXF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tensorflow==2.12.0\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3UjaLXi-7h0v",
    "outputId": "9d6e6aa2-ed4f-49cb-9d54-161cfd2b8507"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==2.12.0\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.68.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.33)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.0)\n",
      "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.33)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
      "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
      "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
      "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
      "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
      "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
      "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
      "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
      "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
      "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
      "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
      "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
      "  Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
      "Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m585.9/585.9 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m78.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m79.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.1/17.1 MB\u001B[0m \u001B[31m98.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m294.6/294.6 kB\u001B[0m \u001B[31m27.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.6/5.6 MB\u001B[0m \u001B[31m113.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m440.7/440.7 kB\u001B[0m \u001B[31m35.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl (79.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.6/79.6 MB\u001B[0m \u001B[31m27.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m115.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: wrapt, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, keras, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.11.0\n",
      "    Uninstalling tensorflow-estimator-2.11.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "  Attempting uninstall: jaxlib\n",
      "    Found existing installation: jaxlib 0.4.33\n",
      "    Uninstalling jaxlib-0.4.33:\n",
      "      Successfully uninstalled jaxlib-0.4.33\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.2\n",
      "    Uninstalling tensorboard-2.11.2:\n",
      "      Successfully uninstalled tensorboard-2.11.2\n",
      "  Attempting uninstall: jax\n",
      "    Found existing installation: jax 0.4.33\n",
      "    Uninstalling jax-0.4.33:\n",
      "      Successfully uninstalled jax-0.4.33\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.11.0\n",
      "    Uninstalling tensorflow-2.11.0:\n",
      "      Successfully uninstalled tensorflow-2.11.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
      "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
      "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
      "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
      "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
      "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.5 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "jax",
         "jaxlib",
         "keras",
         "numpy",
         "tensorboard",
         "tensorflow",
         "wrapt"
        ]
       },
       "id": "65f17ca680034fe38433376342dfb792"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tensorflow-gpu"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3LvF_-P71uq",
    "outputId": "acbda5a5-0364-4163-8b84-1cb95ac6ec41"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py egg_info\u001B[0m did not run successfully.\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m╰─>\u001B[0m See above for output.\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25herror\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\n",
      "\n",
      "\u001B[31m×\u001B[0m Encountered error while generating package metadata.\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\n",
      "\n",
      "\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001B[1;36mhint\u001B[0m: See above for details.\n"
     ]
    }
   ]
  }
 ]
}
